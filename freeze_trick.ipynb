{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a044e0-37b2-4ae9-b7b1-b7abd1c886c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install bitsandbytes-cuda113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d0f729-f0e9-47f0-af9b-81199bec9cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /home/jovyan/.imgenv-gotnee20b-0/lib/python3.7/site-packages (0.10.28)\n",
      "Requirement already satisfied: PyYAML in /home/user/conda/lib/python3.7/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/jovyan/.imgenv-gotnee20b-0/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: pathtools in /home/jovyan/.imgenv-gotnee20b-0/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/jovyan/.imgenv-gotnee20b-0/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/user/conda/lib/python3.7/site-packages (from wandb) (3.19.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/user/conda/lib/python3.7/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/user/conda/lib/python3.7/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/jovyan/.imgenv-gotnee20b-0/lib/python3.7/site-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /home/jovyan/.imgenv-gotnee20b-0/lib/python3.7/site-packages (from wandb) (1.5.8)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/user/conda/lib/python3.7/site-packages (from wandb) (3.1.26)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/user/conda/lib/python3.7/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /home/user/conda/lib/python3.7/site-packages (from wandb) (5.2.0)\n",
      "Requirement already satisfied: Click>=7.0 in /home/user/conda/lib/python3.7/site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /home/jovyan/.imgenv-gotnee20b-0/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: importlib-metadata in /home/user/conda/lib/python3.7/site-packages (from Click>=7.0->wandb) (4.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/user/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/user/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=7.0->wandb) (3.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47aff858-055f-47da-afcb-08f8c76b0a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/user/conda/lib/python3.7/site-packages (from pytorch-lightning) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/user/conda/lib/python3.7/site-packages (from pytorch-lightning) (4.0.1)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/user/conda/lib/python3.7/site-packages (from pytorch-lightning) (2022.1.0)\n",
      "Requirement already satisfied: torch>=1.8.* in /home/user/conda/lib/python3.7/site-packages (from pytorch-lightning) (1.9.1+cu111)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/user/conda/lib/python3.7/site-packages (from pytorch-lightning) (4.62.3)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/user/conda/lib/python3.7/site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/jovyan/.imgenv-gpt-neo-4gpu-0/lib/python3.7/site-packages (from pytorch-lightning) (1.18.0)\n",
      "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
      "  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting torchmetrics>=0.4.1\n",
      "  Using cached torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/user/conda/lib/python3.7/site-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: aiohttp in /home/user/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.1)\n",
      "Requirement already satisfied: requests in /home/user/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/user/conda/lib/python3.7/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.7)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/user/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/user/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.43.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/user/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.19.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/user/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/jovyan/.imgenv-gpt-neo-4gpu-0/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (60.5.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/user/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/user/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/user/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/jovyan/.imgenv-gpt-neo-4gpu-0/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/user/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/user/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/user/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/user/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/user/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/user/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/user/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/user/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/user/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (0.13.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/user/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/user/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/user/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n",
      "Installing collected packages: pyDeprecate, torchmetrics, pytorch-lightning\n",
      "Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.6.0 torchmetrics-0.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c936cda-f846-4f1a-8484-7dd87686b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "\n",
    "device = 'cuda:1'\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\").to(device)#results/checkpoint-45000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd5d93eb-1b59-4ed1-975a-4e983cc7d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tokenizer.encode_plus('how to poop',return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b112b1bf-654b-459d-b586-93ee995c8e5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:1! (when checking arugment for argument index in method wrapper_index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3412548/292156476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3412548/2274494651.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-gpt-neo-4gpu-0/lib/python3.7/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         )\n\u001b[1;32m    756\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-gpt-neo-4gpu-0/lib/python3.7/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:1! (when checking arugment for argument index in method wrapper_index_select)"
     ]
    }
   ],
   "source": [
    "\n",
    "input_ids = enc['input_ids']\n",
    "attention_mask = enc['attention_mask']\n",
    "#model(input_ids=input_ids, labels=input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1580e5a-7bc7-407d-b644-61bd77af5a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116c6a94-81be-4858-9496-3399aa4c6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "import pytorch_lightning as pl\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "df = pd.read_csv(\"../data_kaggle/sudoku.csv\")\n",
    "\n",
    "X = df.quizzes.values\n",
    "y = df.solutions.values\n",
    "\n",
    "prompt = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "map_values = list(tokenizer(prompt, return_tensors=\"pt\").input_ids.numpy().flatten())\n",
    "map_value_to_token = dict(zip(prompt, map_values))\n",
    "map_token_to_value = {map_value_to_token[x]:x for x in map_value_to_token}\n",
    "bos = tokenizer.encode(tokenizer.bos_token)[0]\n",
    "map_token_to_value[bos] = ''\n",
    "\n",
    "# [bos] + [:-1]\n",
    "X = [list(map(map_value_to_token.__getitem__, x)) for x in X]\n",
    "y = [list(map(map_value_to_token.__getitem__, x)) for x in y]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5069dd60-b307-4e19-bac2-67ab3a9b99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class SudokuDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, Y):\n",
    "        \n",
    "        self.exampls = []\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "        \n",
    "        #tt = torch.zeros((1, 4), dtype=torch.int)\n",
    "        for x, y in zip(X, Y):\n",
    "            self.input_ids.append(torch.tensor(x).reshape((1, 81)))\n",
    "            \n",
    "            self.labels.append(torch.tensor(y).reshape((1, 81)))\n",
    "            \n",
    "            self.attn_masks.append(torch.ones((1, 81), dtype=torch.int64))\n",
    "            \n",
    "            self.exampls.append(torch.cat((torch.tensor(x),torch.tensor(y)),0))\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx], self.labels[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f8f1f4-e59d-432e-9b0e-e3e3063a074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SudokuDataset(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df7246-f5d7-4a91-9237-810a34fa053f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ca9ea8-4080-4d24-ad28-6c2bd20adca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.overwrite_cache = False\n",
    "        #self.tokenizer_name = \"EleutherAI/gpt-neo-2.7B\"\n",
    "        #self.model_name_or_path = 'EleutherAI/gpt-neo-2.7B'\n",
    "        self.output_dir = \"sudoku_freezed_2.7\"\n",
    "        self.deepspeed=False\n",
    "        if not self.deepspeed:\n",
    "          self.fp16 = True\n",
    "          self.fp16_opt_level = \"O1\"\n",
    "          self.n_gpu = 0\n",
    "          self.local_rank = 1\n",
    "          self.device = torch.device(\"cuda\")\n",
    "        \n",
    "        self.weight_decay = 0.01\n",
    "        self.eval_batch_size = 2\n",
    "        self.train_batch_size = 2\n",
    "        self.gradient_accumulation_steps = 5\n",
    "        self.lr = 1e-5\n",
    "        self.warmup_steps = 1\n",
    "        self.adam_epsilon = 1e-8\n",
    "        self.max_grad_norm = .3\n",
    "        self.epochs = 100\n",
    "        self.eval_steps = 2000\n",
    "        self.seed = 42\n",
    "        \n",
    "args = Args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0b50b7-b96e-4e8c-987e-bf614c8ddb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuDataModule(pl.LightningDataModule):\n",
    "\n",
    "  def __init__(self, X_train, X_test, y_train, y_test, args):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.X_train = X_train\n",
    "    self.y_train = y_train\n",
    "    self.X_test = X_test\n",
    "    self.y_test = y_test\n",
    " \n",
    "   \n",
    "\n",
    "  def setup(self, stage=None):\n",
    "    self.train_dataset = SudokuDataset(self.X_train,self.y_train)\n",
    "\n",
    "    self.test_dataset = SudokuDataset(self.X_test,self.y_test)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.train_dataset,\n",
    "      batch_size=args.train_batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=2\n",
    "    )\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=args.eval_batch_size,\n",
    "      num_workers=2\n",
    "    )\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.eval_batch_size,\n",
    "      num_workers=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c26abd-0b80-4a0b-a92d-a1beef3e1f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = SudokuDataModule(X_train, X_test, y_train, y_test, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add2e36d-a49e-4658-b91c-dbe0eb389663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "#import bitsandbytes as bnb\n",
    "\n",
    "def _save_checkpoint(args, model, tokenizer,it):\n",
    "    output_dir = os.path.join(args.output_dir, f\"checkpoint_{it}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Saving model checkpoint to {output_dir}\")\n",
    "\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
    "\n",
    "def freeze(\n",
    "    model,\n",
    "    freeze_emb=True,\n",
    "    freeze_ln=False,\n",
    "    freeze_attn=False,\n",
    "    freeze_ff=False,\n",
    "    freeze_other=False,\n",
    "):\n",
    "    \n",
    "    for name, p in model.named_parameters():\n",
    "    # freeze all parameters except the layernorm and positional embeddings\n",
    "       \n",
    "       \n",
    "        \n",
    "        name = name.lower()\n",
    "        if 'ln' in name or 'norm' in name:\n",
    "            p.requires_grad = not freeze_ln\n",
    "        elif 'embeddings' in name:\n",
    "            p.requires_grad = not freeze_emb\n",
    "        elif 'mlp' in name:\n",
    "            p.requires_grad = not freeze_ff\n",
    "        elif 'attn' in name:\n",
    "            p.requires_grad = not freeze_attn\n",
    "        else:\n",
    "            p.requires_grad = not freeze_other\n",
    "           \n",
    "    return model\n",
    "\n",
    "def collate(examples):\n",
    "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#optimizer =  bnb.optim.Adam8bit(model.parameters(), lr=args.lr,eps=args.adam_epsilon, betas=(0.9, 0.995))\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=args.lr, \n",
    "#                                                final_div_factor=500,  \n",
    "#                                               steps_per_epoch=len(train_dataloader),\n",
    "#                                               epochs=args.epochs \n",
    "#                                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a396dfd-b53c-499d-91e7-c806b72d32fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/notebook/utils.py:282: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexwortega\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">generous-frog-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/alexwortega/sudoku\" target=\"_blank\">https://wandb.ai/alexwortega/sudoku</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/alexwortega/sudoku/runs/3pp7bgcv\" target=\"_blank\">https://wandb.ai/alexwortega/sudoku/runs/3pp7bgcv</a><br/>\n",
       "                Run data is saved locally in <code>/home/jovyan/Nikolich/serega/code/wandb/run-20220405_164657-3pp7bgcv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(3pp7bgcv)</h1><iframe src=\"https://wandb.ai/alexwortega/sudoku/runs/3pp7bgcv\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f2837fffe90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key='1d66b96a01b6d89816f35c71af8991f35ac96153')\n",
    "wandb.init(project = 'sudoku', entity = \"alexwortega\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9652cd9-171e-4d66-889d-8aa299c0b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentTagger(pl.LightningModule):\n",
    "\n",
    "  def __init__(self, args, n_training_steps=None, n_warmup_steps=None):\n",
    "    super().__init__()\n",
    "    self.gpt = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "    \n",
    "    self.n_training_steps = n_training_steps\n",
    "    self.n_warmup_steps = n_warmup_steps\n",
    "    \n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels):\n",
    "    loss = self.gpt(input_ids=input_ids, labels=input_ids, attention_mask=attention_mask)[0]\n",
    "   \n",
    "   \n",
    "    return loss\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    \n",
    "    loss = self.gpt(input_ids=input_ids, labels=input_ids, attention_mask=attention_mask)[0]\n",
    "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    \n",
    "    loss = self.gpt(input_ids=input_ids, labels=input_ids, attention_mask=attention_mask)[0]\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    \n",
    "    loss = self.gpt(input_ids=input_ids, labels=input_ids, attention_mask=attention_mask)[0]\n",
    "    \n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "\n",
    "  def training_epoch_end(self, outputs):\n",
    "    \n",
    "    pass\n",
    "\n",
    "    #for i, name in enumerate(LABEL_COLUMNS):\n",
    "    # class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
    "    #  self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
    "\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "\n",
    "    optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "      optimizer,\n",
    "      num_warmup_steps=self.n_warmup_steps,\n",
    "      num_training_steps=self.n_training_steps\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "      optimizer=optimizer,\n",
    "      lr_scheduler=dict(\n",
    "        scheduler=scheduler,\n",
    "        interval='step'\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32624351-289b-468a-a054-8e92458cbbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(X_train) // args.train_batch_size\n",
    "total_training_steps = steps_per_epoch * args.epochs\n",
    "warmup_steps = total_training_steps // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfc10d-b756-424c-b21d-fa2f3dc50921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90e62ca7-cbe1-4f99-96dd-ccbd2ac2c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToxicCommentTagger(\n",
    "  args=args,\n",
    "  n_warmup_steps=warmup_steps,\n",
    "  n_training_steps=total_training_steps \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8606a9f2-ae69-46fc-9cc7-20b56c6e12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=\"checkpoints\",\n",
    "  filename=\"best-checkpoint\",\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b867531e-2515-44f7-b32b-5abd58d1c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "205016be-9183-4754-8103-549a3f49a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:440: UserWarning: The flag `devices=[1]` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:152: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f2837d87950>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f2837d87950>)`.\n",
      "  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n",
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=30)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "  logger=wandb_logger,\n",
    "  checkpoint_callback=checkpoint_callback,\n",
    "  callbacks=[early_stopping_callback],\n",
    "  max_epochs=2,\n",
    "  gpus=1,\n",
    "  devices=[1],\n",
    "  progress_bar_refresh_rate=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2ab61-b69e-496b-aca3-3cdac884213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/jovyan/.imgenv-gpt-neo-4gpu-0/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "\n",
      "  | Name | Type              | Params\n",
      "-------------------------------------------\n",
      "0 | gpt  | GPTNeoForCausalLM | 2.7 B \n",
      "-------------------------------------------\n",
      "2.7 B     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 B     Total params\n",
      "10,605.230Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9103fa1b870d4d0b8a72673bb2ab751f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/loggers/wandb.py:346: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  \"There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse\"\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aceb1dc-1385-4453-a47c-e38c3c631964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
